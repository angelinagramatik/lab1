{"cells":[{"metadata":{},"cell_type":"markdown","source":"Classification of clothing items for the task of [iMaterialist (Fashion) 2019 at FGVC6](http://https://www.kaggle.com/c/imaterialist-fashion-2019-FGVC6) dataset on Keras.\n"},{"metadata":{},"cell_type":"markdown","source":"**Loading Libraries**"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import os\nimport random\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\nplt.style.use(\"ggplot\")\n\nfrom tqdm import tqdm_notebook, tnrange, tqdm\nfrom skimage.io import imread, imshow, concatenate_images\nfrom skimage.transform import resize\nfrom skimage.morphology import label\nfrom sklearn.model_selection import train_test_split\n\nfrom PIL import Image\nimport pandas as pd\nimport gc\nimport glob\nimport shutil\nimport json\nfrom imgaug import augmenters as iaa\nimport imgaug as ia\nfrom pathlib import Path\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom keras import backend as K\nimport keras\n\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.layers.core import Activation\nfrom keras.layers.core import Flatten\nfrom keras.layers.core import Dropout\nfrom keras.layers.core import Dense\nfrom keras.models import Sequential\nfrom keras.optimizers import Adam\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n\nfrom keras.losses import binary_crossentropy\nfrom keras.engine import InputSpec\nfrom keras.engine.training import Model\nfrom keras.callbacks import Callback, EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom keras.utils import Sequence\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Defining some important variables**"},{"metadata":{"trusted":true},"cell_type":"code","source":"img_height = 512 \nimg_width = 512 \nimg_channels = 3 \nbatch_size = 8","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"seed = 10\nnp.random.seed(seed)\nrandom.seed(seed)\nos.environ['PYTHONHASHSEED'] = str(seed)\nnp.random.seed(seed)\ntf.set_random_seed(seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_dir = \"../input/imaterialist-fashion-2019-FGVC6/\"\nimage_dir = \"../input/imaterialist-fashion-2019-FGVC6/train/\"\nmodel_weights = \"../input/weights-unet/unet_seresnet50_weights.h5\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Data analysis**\n\n* There are 333,415 total data.\n* Considering only one unique image, the number of images is 45,625 total.\n* One image can correspond to multiple classes.\n* Not all clothing items are marked at the photos.\n* There are 46 categories and 92 attributes."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(input_dir + \"train.csv\")\nprint(\"Number of data items: \", train_df.shape[0])\nprint(\"Number of unique images:\",len(set(train_df['ImageId'])))\n\njson_data = open(input_dir + \"label_descriptions.json\").read()\nlabel_descriptions = json.loads(json_data)\ncategories_label_df = pd.DataFrame(label_descriptions['categories'])\nprint(\"The number of categories: \",len(categories_label_df))\nclasses_names = [x['name'] for x in label_descriptions['categories']]\nprint(classes_names)\n\nattributes_label_df = pd.DataFrame(label_descriptions['attributes'])\nprint(\"The number of attributes: \",len(attributes_label_df))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df_ImageId_count = train_df['ImageId'].value_counts()\nplt.figure(figsize=(20, 7))\nplt.title('image labels count', size=20)\nplt.xlabel('', size=15);plt.ylabel('', size=15);\nsns.countplot(train_df_ImageId_count)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['Category'] = train_df['ClassId'].apply(lambda x: int(x.split(\"_\")[0]))\ngroupby_category = train_df.groupby('Category')['ImageId'].count()\ngroupby_category.index = map(int, groupby_category.index)\ngroupby_category = groupby_category.sort_index()\ngroupby_category[:5]\n\nfig = plt.figure(figsize=(20, 7))\nx = groupby_category.index\ny = groupby_category.values\n\nsns.barplot(x,y)\nplt.title(\"Number of data items by category\", fontsize=20)\nplt.xlabel(\"Category\", fontsize=20)\nplt.ylabel(\"# of masks\", fontsize=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label_description_categories = pd.DataFrame(label_descriptions['categories'])\n\nlabel_merge = categories_label_df[['id', 'name']].astype(str).astype(object)\ntrain_classid = pd.DataFrame({'ClassId':train_df['ClassId'].apply(lambda x: x[:2].replace('_', ''))})\nlabel_merge = label_description_categories[['id', 'name']].astype(str).astype(object)\n\n\ntrain_df_name = train_classid.merge(label_merge, left_on='ClassId', right_on='id', how='left')\nsum1 = train_df_name.shape[0]\nratio1 = np.round(train_df_name.groupby(['ClassId', 'name']).count().sort_values(by='id', ascending=False).rename(columns = {'id':'count'})/sum1 * 100, 2)\ntrain_df_name_stat = train_df_name.groupby(['ClassId', 'name']).count().sort_values(by='id', ascending=False).rename(columns = {'id':'count'}).reset_index()\ntrain_df_name_stat['ratio(%)'] = ratio1.values\ntrain_df_name_stat = train_df_name_stat.head(22)\n\nclasses = [x for x in train_df_name_stat['ClassId']]\nprint(classes)\nn_classes = len(classes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"int_to_classes = {k:v for k, v in zip(range(0, len(classes)), classes)}\nclasses_to_int = {v:k for k, v in zip(range(0, len(classes)), classes)}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(input_dir + \"train.csv\")\ndf = df[df['ClassId'].isin(classes)].head(20000)\ndf['CategoryId'] = df.ClassId.apply(lambda x: str(x).split(\"_\")[0])\ntemp_df = df.groupby('ImageId')['EncodedPixels', 'CategoryId'].agg(lambda x: list(x)).reset_index()\nsize_df = df.groupby('ImageId')['Height', 'Width'].mean().reset_index()\ndf = temp_df.merge(size_df, on='ImageId', how='left')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Loading data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MultiLabelBinarizer\nmlb = MultiLabelBinarizer(classes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nclass DataLoader():\n    \n    def __init__(self, img_dir, df, visualize=True):\n        \n        self.img_dir = img_dir\n        self.df = df\n        self.images = []\n        self.labels = []\n        self.visualize = visualize\n    \n    def get_data(self):       \n\n        for index, row in tqdm(self.df.iterrows(), total=len(self.df)):\n            \n            image_id = row['ImageId']\n            image_path = os.path.join(self.img_dir, image_id)\n            self.images.append(image_path)\n            \n            mask = []\n            img_labels = []\n            for m, (annotation, label) in enumerate(zip(row['EncodedPixels'], row['CategoryId'])):\n                img_labels.append(classes[classes_to_int[label]])\n\n            img_labels = mlb.fit_transform([convert(img_labels)])\n            self.labels.append(img_labels)\n            \n            if self.visualize:\n                if index % 100 == 0:\n                    self.visualize_results(image_path, img_labels)\n                    \n        return self.images, self.labels\n                    \n    \n    def rle_decode(self, mask_rle, shape):\n        shape = (shape[1], shape[0])\n        s = mask_rle.split()\n        starts, lengths = [np.asarray(x, dtype=int) for x in (s[0::2], s[1::2])]\n        starts -= 1\n        ends = starts + lengths\n        img = np.zeros(shape[0] * shape[1], dtype=np.uint8)\n        for lo, hi in zip(starts, ends):\n            img[lo:hi] = 1\n        return img.reshape(shape).T \n    \n    \n    def visualize_results(self, image_path, mask):\n        img = Image.open(image_path).convert(\"RGB\")\n        plt.imshow(img)\n        print(mask)\n        mask = [mlb.classes_[i] for i in mask]\n        plt.title(mask)\n        plt.show()\n\n    def get_datalen(self):\n        return len(self.images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def convert(list): \n    return (*list, ) \n\ndataloader = DataLoader(image_dir, df, False)\nimages, labels = dataloader.get_data()\nprint(len(images))\nprint(len(labels))\nprint(mlb.classes)\nprint(labels[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Splitting data into train and test**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_image, valid_image, train_labels, valid_labels = train_test_split(\n        images, labels,\n        test_size = 0.3, \n        random_state=42\n)\n\nprint('{} training images && {} labels'.format(len(train_image), len(train_labels)))\nprint('{} validation images && {} labels'.format(len(valid_image), len(valid_labels)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Data Generator**"},{"metadata":{"trusted":true},"cell_type":"code","source":"class DataGenerator(keras.utils.Sequence):\n\n    def __init__(self, image_filenames, labels, batch_size):\n        \n        self.image_filenames, self.labels = image_filenames, labels\n        self.batch_size = batch_size\n        \n    def __len__(self):\n        return len(self.image_filenames) // self.batch_size\n    \n    def __getitem__(self, idx):\n        \n        batch_x = self.image_filenames[idx * self.batch_size:(idx + 1) * self.batch_size]\n        batch_y = self.labels[idx * self.batch_size:(idx + 1) * self.batch_size]\n        \n        batch_X = []\n        batch_Y = []\n\n        for filename in batch_x:\n            with Image.open(filename).convert('RGB') as img:\n                img = cv2.resize(np.asarray(img), (img_height, img_width))\n                img = np.asarray(img) / 255.0\n                batch_X.append(img)\n\n        batch_X = np.asarray(batch_X)\n        batch_Y = np.asarray(np.squeeze(batch_y, axis=1))\n\n        return batch_X, batch_Y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator = DataGenerator(train_image, train_labels, batch_size)\nvalid_generator = DataGenerator(valid_image, valid_labels, batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img, labels = train_generator.__getitem__(1)\nprint(labels.shape)\nprint(img.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Building a model**\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"class SmallerVGGNet:\n    @staticmethod\n    def build(width, height, depth, classes, finalAct=\"softmax\"):\n        model = Sequential()\n        inputShape = (height, width, depth)\n        chanDim = -1\n \n        if K.image_data_format() == \"channels_first\":\n            inputShape = (depth, height, width)\n            chanDim = 1\n        \n        # CONV => RELU => POOL\n        model.add(Conv2D(32, (3, 3), padding=\"same\",\n            input_shape=inputShape))\n        model.add(Activation(\"relu\"))\n        model.add(BatchNormalization(axis=chanDim))\n        model.add(MaxPooling2D(pool_size=(3, 3)))\n        model.add(Dropout(0.25))\n\n        # (CONV => RELU) * 2 => POOL\n        model.add(Conv2D(64, (3, 3), padding=\"same\"))\n        model.add(Activation(\"relu\"))\n        model.add(BatchNormalization(axis=chanDim))\n        model.add(Conv2D(64, (3, 3), padding=\"same\"))\n        model.add(Activation(\"relu\"))\n        model.add(BatchNormalization(axis=chanDim))\n        model.add(MaxPooling2D(pool_size=(2, 2)))\n        model.add(Dropout(0.25))\n \n        # (CONV => RELU) * 2 => POOL\n        model.add(Conv2D(128, (3, 3), padding=\"same\"))\n        model.add(Activation(\"relu\"))\n        model.add(BatchNormalization(axis=chanDim))\n        model.add(Conv2D(128, (3, 3), padding=\"same\"))\n        model.add(Activation(\"relu\"))\n        model.add(BatchNormalization(axis=chanDim))\n        model.add(MaxPooling2D(pool_size=(2, 2)))\n        model.add(Dropout(0.25))\n\n        # first (and only) set of FC => RELU layers\n        model.add(Flatten())\n        model.add(Dense(1024))\n        model.add(Activation(\"relu\"))\n        model.add(BatchNormalization())\n        model.add(Dropout(0.5))\n\n        model.add(Dense(classes))\n        model.add(Activation(finalAct))\n\n        # return the constructed network architecture\n        return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = SmallerVGGNet.build(\n    width=img_width, height=img_height,\n    depth=img_channels, classes=len(mlb.classes_),\n    finalAct=\"sigmoid\")\n\nopt = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, decay=0)\n\nmodel.compile(loss=\"binary_crossentropy\", optimizer=opt,\n    metrics=[\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class CustomCallback(Callback):\n    def __init__(self, model):\n        self.batch_size = 10\n        self.generator = DataGenerator(valid_image, valid_labels, self.batch_size)\n        self.model = model\n\n    def on_epoch_end(self, epoch, logs={}):\n        \n        X, y_true = self.generator.__getitem__(0)\n        threshold = 0.5\n        \n        fig, ax = plt.subplots(10, 2, figsize = (40, 60))\n        \n        y_pred = model.predict(X)\n        count = 0\n        \n        for i in range(10):\n            img = X[i]\n            label_true = y_true[i]\n            label_pred = y_pred[i]\n\n            ax[i][count].imshow(img)\n            true_idxs = np.where(label_true == 1)[0]\n            true_label = [classes_names[int(classes[j])] for j in true_idxs]\n            ax[i][count].set_title(true_label)\n            ax[i][count].axis('off')\n            \n            idxs = np.argsort(label_pred)[::-1][:5]\n            labels = []\n\n            for (k, j) in enumerate(idxs):\n                label = \"{}: {:.2f}%\".format(classes_names[int(classes[j])], label_pred[j] * 100)\n                labels.append(label)\n\n            ax[i][count + 1].imshow(img)\n            ax[i][count + 1].set_title(labels)\n            ax[i][count + 1].axis('off')\n        \n        plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Training the model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 25\nkeras.backend.get_session().run(tf.global_variables_initializer())\n\nhistory = model.fit_generator(\n      generator = train_generator,\n      epochs = epochs,\n      callbacks = [\n           CustomCallback(model),\n           ModelCheckpoint('unet_weights_epoch-{epoch:02d}_loss-{loss:.4f}.h5',\n                           monitor='val_loss',\n                           verbose=1,\n                           save_best_only=True,\n                           save_weights_only=True,\n                           mode='auto',\n                           period=1),\n           ReduceLROnPlateau(monitor='val_loss',\n                             factor=0.5,\n                             patience=0,\n                             epsilon=0.001,\n                             cooldown=0)\n          ],\n      validation_data = valid_generator,\n      max_queue_size=10\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def visualize_history(history):\n    plt.figure(figsize=(16,4))\n    plt.subplot(1,2,1)\n    plt.plot(history.history['acc'][1:])\n    plt.plot(history.history['val_acc'][1:])\n    plt.ylabel('acc')\n    plt.xlabel('epoch')\n    plt.legend(['train','Validation'], loc='upper left')\n\n    plt.title('model accuracy')\n\n    plt.subplot(1,2,2)\n    plt.plot(history.history['loss'][1:])\n    plt.plot(history.history['val_loss'][1:])\n    plt.ylabel('val_loss')\n    plt.xlabel('epoch')\n    plt.legend(['train','Validation'], loc='upper left')\n    plt.title('model loss')\n    gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"visualize_history(history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_results(index):\n    \n    X, y_true = valid_generator.__getitem__(index)\n        \n    fig, ax = plt.subplots(8, 2, figsize = (40, 60))\n\n    y_pred = model.predict(X)\n    count = 0\n\n    for i in range(len(X)):\n        img = X[i]\n        label_true = y_true[i]\n        label_pred = y_pred[i]\n\n        ax[i][count].imshow(img)\n        true_idxs = np.where(label_true == 1)[0]\n        true_label = [classes_names[int(classes[j])] for j in true_idxs]\n        ax[i][count].set_title(true_label)\n        ax[i][count].axis('off')\n\n        idxs = np.argsort(label_pred)[::-1][:5]\n        labels = []\n\n        for (k, j) in enumerate(idxs):\n            label = \"{}: {:.2f}%\".format(classes_names[int(classes[j])], label_pred[j] * 100)\n            labels.append(label)\n\n        ax[i][count + 1].imshow(img)\n        ax[i][count + 1].set_title(labels)\n        ax[i][count + 1].axis('off')\n\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_results(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}