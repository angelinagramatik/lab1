{"cells":[{"metadata":{},"cell_type":"markdown","source":"Segmentation model for clothing for the task of [iMaterialist (Fashion) 2019 at FGVC6](http://https://www.kaggle.com/c/imaterialist-fashion-2019-FGVC6) dataset on Keras using UNet and SeResNet50 as a backbone.\n"},{"metadata":{},"cell_type":"markdown","source":"**Loading Libraries**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"! pip install git+https://github.com/qubvel/segmentation_models","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import os\nimport random\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\nplt.style.use(\"ggplot\")\n\nfrom tqdm import tqdm_notebook, tnrange, tqdm\nfrom skimage.io import imread, imshow, concatenate_images\nfrom skimage.transform import resize\nfrom skimage.morphology import label\nfrom sklearn.model_selection import train_test_split\n\nfrom PIL import Image\nimport pandas as pd\nimport gc\nimport glob\nimport shutil\nimport json\nfrom imgaug import augmenters as iaa\nimport imgaug as ia\nfrom pathlib import Path\nimport seaborn as sns\nimport albumentations as albu","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom keras import backend as K\nimport keras\n\nfrom keras.models import Model, load_model\nfrom keras.layers import Input, Conv2D, Conv2DTranspose, Dropout,BatchNormalization\nfrom keras.layers import Concatenate, MaxPooling2D, LeakyReLU\nfrom keras.layers import UpSampling2D, Add, ZeroPadding2D\nfrom keras.layers import GlobalAveragePooling2D, Reshape, Dense, Permute\nfrom keras.layers.merge import concatenate, add, multiply\nfrom keras.layers.core import Dense, Lambda, Activation, SpatialDropout2D\nfrom keras.optimizers import Adam\n\nfrom keras.losses import binary_crossentropy\nfrom keras.engine.training import Model\nfrom keras.callbacks import Callback, EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom keras.utils import Sequence\n\nfrom segmentation_models import Unet\nfrom segmentation_models.losses import bce_jaccard_loss\nfrom segmentation_models.metrics import iou_score\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Defining some important variables**"},{"metadata":{"trusted":true},"cell_type":"code","source":"img_height = 512 \nimg_width = 512\nimg_channels = 3 \nn_classes = 1 \nbatch_size = 8\nBACKBONE = 'seresnet50'\npreprocess_input = BACKBONE","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"seed = 10\nnp.random.seed(seed)\nrandom.seed(seed)\nos.environ['PYTHONHASHSEED'] = str(seed)\nnp.random.seed(seed)\ntf.set_random_seed(seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_dir = \"../input/imaterialist-fashion-2019-FGVC6/\"\nimage_dir = \"../input/imaterialist-fashion-2019-FGVC6/train/\"\nmodel_weights = \"../input/weights-unet/unet_seresnet50_weights.h5\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Data analysis**\n\n* There are 333,415 total data.\n* Considering only one unique image, the number of images is 45,625 total.\n* One image can correspond to multiple classes.\n* Not all clothing items are marked at the photos.\n* There are 46 categories and 92 attributes."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(input_dir + \"train.csv\")\nprint(\"Number of data items: \", train_df.shape[0])\nprint(\"Number of unique images:\",len(set(train_df['ImageId'])))\n\njson_data = open(input_dir + \"label_descriptions.json\").read()\nlabel_descriptions = json.loads(json_data)\ncategories_label_df = pd.DataFrame(label_descriptions['categories'])\nprint(\"The number of categories: \",len(categories_label_df))\n\nattributes_label_df = pd.DataFrame(label_descriptions['attributes'])\nprint(\"The number of attributes: \",len(attributes_label_df))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df_ImageId_count = train_df['ImageId'].value_counts()\nplt.figure(figsize=(20, 7))\nplt.title('image labels count', size=20)\nplt.xlabel('', size=15);plt.ylabel('', size=15);\nsns.countplot(train_df_ImageId_count)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['Category'] = train_df['ClassId'].apply(lambda x: int(x.split(\"_\")[0]))\ngroupby_category = train_df.groupby('Category')['ImageId'].count()\ngroupby_category.index = map(int, groupby_category.index)\ngroupby_category = groupby_category.sort_index()\ngroupby_category[:5]\n\nfig = plt.figure(figsize=(20, 7))\nx = groupby_category.index\ny = groupby_category.values\n\nsns.barplot(x,y)\nplt.title(\"Number of data items by category\", fontsize=20)\nplt.xlabel(\"Category\", fontsize=20)\nplt.ylabel(\"# of masks\", fontsize=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Loading data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(input_dir + \"train.csv\").head(10000)\ndf['CategoryId'] = df.ClassId.apply(lambda x: str(x).split(\"_\")[0])\ntemp_df = df.groupby('ImageId')['EncodedPixels', 'CategoryId'].agg(lambda x: list(x)).reset_index()\nsize_df = df.groupby('ImageId')['Height', 'Width'].mean().reset_index()\ndf = temp_df.merge(size_df, on='ImageId', how='left')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DataLoader():\n    \n    def __init__(self, img_dir, df, visualize=True):\n        \n        self.img_dir = img_dir\n        self.df = df\n        self.images = []\n        self.masks = []\n        self.visualize = visualize\n    \n    def get_data(self):       \n\n        for index, row in tqdm(self.df.iterrows(), total=len(self.df)):\n            \n            image_id = row['ImageId']\n            image_path = os.path.join(self.img_dir, image_id)\n            self.images.append(image_path)\n            \n            mask = []\n            for m, (annotation, label) in enumerate(zip(row['EncodedPixels'], row['CategoryId'])):\n                sub_mask = self.rle_decode(annotation, (row[\"Height\"], row[\"Width\"]))\n                sub_mask = Image.fromarray(sub_mask)\n                mask.append(np.asarray(sub_mask))\n            self.masks.append(sum(mask))    \n            \n            if self.visualize:\n                if index % 100 == 0:\n                    self.visualize_results(image_path, mask)\n                    \n        return self.images, self.masks\n                    \n    \n    def rle_decode(self, mask_rle, shape):\n        shape = (shape[1], shape[0])\n        s = mask_rle.split()\n        starts, lengths = [np.asarray(x, dtype=int) for x in (s[0::2], s[1::2])]\n        starts -= 1\n        ends = starts + lengths\n        img = np.zeros(shape[0] * shape[1], dtype=np.uint8)\n        for lo, hi in zip(starts, ends):\n            img[lo:hi] = 1\n        return img.reshape(shape).T \n    \n    \n    def visualize_results(self, image_path, mask):\n        plt.subplot(1, 2, 1)\n        img = Image.open(image_path).convert(\"RGB\")\n        plt.imshow(img)\n        plt.subplot(1, 2, 2)\n        plt.imshow(sum(mask), cmap=\"Blues_r\")\n        plt.show()\n\n    def get_datalen(self):\n        return len(self.images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataloader = DataLoader(image_dir, df)\nimages, masks = dataloader.get_data()\nprint(dataloader.get_datalen())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Splitting data into train and test**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_image, valid_image, train_masks, valid_masks = train_test_split(\n        images, masks,\n        test_size = 0.2, \n        random_state=42\n)\n\nprint('{} training images && {} masks'.format(len(train_image), len(train_masks)))\nprint('{} validation images && {} masks'.format(len(valid_image), len(valid_masks)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Data visualization**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def visualize(train_image, train_labels):\n    ix = random.randint(0, len(train_image))\n\n    pil_im = np.asarray(Image.open(train_image[ix], 'r'))\n    pil_mask = train_labels[ix]\n    pil_im = cv2.resize(np.asarray(pil_im), (img_height, img_width))\n    pil_mask = cv2.resize(np.asarray(pil_mask), (img_height, img_width))\n\n    print(pil_mask.shape)\n\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (40, 30))\n\n    ax1.imshow(pil_im)\n    ax1.contour(np.squeeze(pil_mask), colors='pink', linewidths = 5)\n    ax1.set_title('Image')\n\n    ax1.imshow(pil_im, cmap=\"bone\")\n    ax2.imshow(pil_mask, alpha=0.5, cmap=\"Reds\", interpolation = 'bilinear')\n    ax2.set_title('Mask')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"visualize(train_image, train_masks)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"visualize(valid_image, valid_masks)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Data Generator**"},{"metadata":{"trusted":true},"cell_type":"code","source":"class DataGenerator(keras.utils.Sequence):\n\n    def __init__(self, image_filenames, labels, batch_size, transforms=None):\n        \n        self.image_filenames, self.labels = image_filenames, labels\n        self.batch_size = batch_size\n        self.transforms = transforms\n        \n    def __len__(self):\n        return len(self.image_filenames) // self.batch_size\n    \n    def __getitem__(self, idx):\n        \n        batch_x = self.image_filenames[idx * self.batch_size:(idx + 1) * self.batch_size]\n        batch_y = self.labels[idx * self.batch_size:(idx + 1) * self.batch_size]\n        \n        batch_X = []\n        batch_Y = []\n        \n        \n        for img, mask in zip(batch_x, batch_y):\n            \n            with Image.open(img).convert('RGB') as img:\n                img = cv2.resize(np.asarray(img), (img_height, img_width))\n                img = np.asarray(img) / 255.0\n\n            img_mask = cv2.resize(np.asarray(mask), (img_height, img_width))\n            img_mask = np.asarray(img_mask) / 255.0\n            img_mask = (img_mask > 0).astype(np.uint8)\n            img_mask = np.expand_dims(img_mask, axis=2)\n            \n            if self.transforms is not None:\n                augmented = transforms(image=img, mask=img_mask)\n                image_augm = augmented['image']\n                mask_augm = augmented['mask'].reshape(img_height, img_width, 1)\n                batch_X.append(image_augm)\n                batch_Y.append(mask_augm)\n            \n            else:\n                batch_X.append(img)\n                batch_Y.append(img_mask)\n            \n       \n        batch_X = np.asarray(batch_X)\n        batch_Y = np.asarray(batch_Y)\n        \n        return batch_X, batch_Y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"transforms = albu.Compose([\n    albu.HorizontalFlip(p=0.25),\n    albu.Transpose(p=0.2),\n    albu.RandomBrightnessContrast(p=0.25),\n    albu.RandomGamma(p=0.25),\n    albu.IAAEmboss(p=0.25),\n    albu.Blur(p=0.2, blur_limit = 3)\n], p = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator = DataGenerator(train_image, train_masks, batch_size, transforms)\nvalid_generator = DataGenerator(valid_image, valid_masks, batch_size)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Building a segmentation model**\n\nPretrained Unet with SeResNet50 encoder"},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model(image_size):\n    model = Unet(BACKBONE, encoder_weights='imagenet', input_shape=image_size)\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"K.clear_session() \n\nmodel = build_model(image_size=(img_height, img_width, img_channels))\n\nadam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, decay=0)\nmodel.compile(optimizer='adam', loss=bce_jaccard_loss, metrics=[iou_score])\n\nprint(model.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class CustomCallback(Callback):\n    def __init__(self, model):\n        self.batch_size = 10\n        self.generator = DataGenerator(valid_image, valid_masks, self.batch_size)\n        self.model = model\n\n    def on_epoch_end(self, epoch, logs={}):\n        \n        X, y_true = self.generator.__getitem__(0)\n        \n        y_pred = model.predict(X)\n        i = 4\n        count = 0\n        img = X[i]\n        mask_true = y_true[i]\n        mask_pred = y_pred[i]\n        mask_binary = (mask_pred > 0.5).astype(np.uint8)\n\n        fig, ax = plt.subplots(1, 4, figsize = (40, 30))\n\n        ax[count].imshow(img)\n        ax[count].set_title('Image')\n\n        ax[count + 1].imshow(mask_true.squeeze(), cmap = 'gray', interpolation = 'bilinear')\n        ax[count + 1].set_title('Mask')\n\n        ax[count + 2].imshow(mask_pred.squeeze(), cmap = 'gray', interpolation = 'bilinear')\n        ax[count + 2].set_title('Predicted_Mask')\n        \n        ax[count + 3].imshow(mask_binary.squeeze(), cmap = 'gray', interpolation = 'bilinear')\n        ax[count + 3].set_title('Binary_Mask')\n\n        plt.show()\n        return","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Training the model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 30\nkeras.backend.get_session().run(tf.global_variables_initializer())\n\nhistory = model.fit_generator(\n      generator = train_generator,\n      epochs = epochs,\n      callbacks = [\n           CustomCallback(model),\n           ModelCheckpoint('unet_weights_epoch-{epoch:02d}_loss-{loss:.4f}.h5',\n                           monitor='val_loss',\n                           verbose=1,\n                           save_best_only=True,\n                           save_weights_only=True,\n                           mode='auto',\n                           period=1),\n           ReduceLROnPlateau(monitor='val_loss',\n                             factor=0.5,\n                             patience=0,\n                             epsilon=0.001,\n                             cooldown=0)\n          ],\n      validation_data = valid_generator,\n      max_queue_size=10\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Saving the trained model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_name = 'unet_seresnet50'\nmodel.save('{}.h5'.format(model_name))\nmodel.save_weights('{}_weights.h5'.format(model_name))\n\nprint()\nprint(\"Model saved under {}.h5\".format(model_name))\nprint(\"Weights also saved separately under {}_weights.h5\".format(model_name))\nprint()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Visualizing the results of the trained model**\n* history of the training: loss and metrics\n* images with corresponding true and predicted masks"},{"metadata":{"trusted":true},"cell_type":"code","source":"def visualize_history(history):\n    plt.figure(figsize=(16,4))\n    plt.subplot(1,2,1)\n    plt.plot(history.history['iou_score'][1:])\n    plt.plot(history.history['val_iou_score'][1:])\n    plt.ylabel('iou')\n    plt.xlabel('epoch')\n    plt.legend(['train','Validation'], loc='upper left')\n\n    plt.title('model IOU')\n\n    plt.subplot(1,2,2)\n    plt.plot(history.history['loss'][1:])\n    plt.plot(history.history['val_loss'][1:])\n    plt.ylabel('val_loss')\n    plt.xlabel('epoch')\n    plt.legend(['train','Validation'], loc='upper left')\n    plt.title('model loss')\n    gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"visualize_history(history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_results(num, photos, labels): \n    \n    batch_size = 10 \n    test_gen = DataGenerator(photos, labels, batch_size)\n\n    X, y_true = test_gen.__getitem__(num)\n    y_pred = model.predict(X)\n    y_pred = (y_pred > 0.4).astype(np.uint8)\n\n    fig, ax = plt.subplots(10, 3, figsize = (40, 100))\n    count = 0\n\n    for i in range(len(X)):\n        count = 0\n\n        img = X[i]\n        mask_true = y_true[i]\n        mask_pred = y_pred[i]\n\n        ax[i][count].imshow(img)\n        ax[i][count].set_title('Image')\n        ax[i][count].contour(mask_pred.squeeze(), colors='yellow', levels=[0.5], linewidths = 3)\n        ax[i][count].axis('off')\n\n        ax[i][count + 1].imshow(mask_true.squeeze(), cmap = 'gray', interpolation = 'bilinear')\n        ax[i][count + 1].set_title('Mask')\n        ax[i][count + 1].axis('off')\n\n        ax[i][count + 2].imshow(mask_pred.squeeze(), alpha=0.5, cmap=\"Reds\")\n        ax[i][count + 2].contour(mask_true.squeeze(), colors='green', levels=[0.5], linewidths = 3)\n        ax[i][count + 2].set_title('Predicted_Mask')\n        ax[i][count + 2].axis('off')\n\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_results(0, valid_image, valid_masks)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_results(1, valid_image, valid_masks)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_results(2, valid_image, valid_masks)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_results(6, train_image, train_masks)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Loading model and testing it on the new data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_weights('unet_seresnet50_weights.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def files(path_img):  \n    input_images = []\n    \n    num = 0\n    for file in os.listdir(path_img):\n        \n        if num == 200:\n            break\n        \n        if os.path.isfile(os.path.join(path_img, file)):\n            input_images.append(os.path.join(path_img, file))\n            num += 1\n            \n    return input_images","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_dir = \"../input/imaterialist-fashion-2019-FGVC6/test/\"\ntest = files(input_dir)\nprint(len(test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_test(X): \n    \n    fig, ax = plt.subplots(10, 2, figsize = (20, 100))\n    count = 0\n\n    for i in range(10):\n        ix = random.randint(0, len(X))\n        count = 0\n\n        img = X[ix]\n        with Image.open(img).convert('RGB') as img:\n                img = cv2.resize(np.asarray(img), (img_height, img_width))\n                img = np.asarray(img) / 255.0\n        \n        y_pred = model.predict(np.expand_dims(img, axis=0))\n        y_pred = (y_pred > 0.4).astype(np.uint8)\n\n        mask_pred = y_pred\n\n        ax[i][count].imshow(img)\n        ax[i][count].set_title('Image')\n        ax[i][count].contour(mask_pred.squeeze(), colors='yellow', levels=[0.5], linewidths = 3)\n        ax[i][count].axis('off')\n\n        ax[i][count + 1].imshow(mask_pred.squeeze(), alpha=0.5, cmap=\"Reds\")\n        ax[i][count + 1].set_title('Predicted_Mask')\n        ax[i][count + 1].axis('off')\n\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_test(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_test(test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Conclusion **\n* UNet with SeResNet50 has the best results comparing to UNet++ and DLA on ResNet50.\n* Not all the data items have correct masks.\n* There are images with a lot of people and masks only for one person.\n* There can be a lot of textures on the images that makes it difficult for segmentation.\n* Not enough resources :c\n\n**Future work**\n* Add item classification\n* Try other backbones "}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}